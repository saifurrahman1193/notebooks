# Characteristics of Big Data

---
## **6 V‚Äôs of Big Data**


| **V**           | **Meaning**                                                             | **Explanation / Example**                                                                  |
| --------------- | ----------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |
| **Volume**      | **Amount/size/quantity/(how much) of data**                             | Massive amounts of data ‚Äî e.g., Facebook generates terabytes of user data daily.           |
| **Variety**     | **Different types/formats/(What kind) of data**                         | Structured (tables), semi-structured (JSON, XML), and unstructured (videos, images, text). |
| **Velocity**    | **Speed/(how fast data moving) of data generation and processing**      | Real-time streaming from IoT devices, financial trades, social media feeds, etc.           |
| **Value**       | **Usefulness/worth/(is data useful) of data for decision-making**       | Data must provide insights, trends, or patterns that help businesses or organizations.     |
| **Variability** | **Inconsistency or unpredictability in data flows (How data changes?)** | Data meaning changes over time ‚Äî e.g., trending topics on Twitter vary hour by hour.       |
| **Veracity**    | **Accuracy/quality/reliability/(How trustworthy) of data**              | Data can be noisy, incomplete, or misleading ‚Äî requires cleaning and validation.           |

---




### Hadoop MapReduce Function? [MeSSiR]


### 1. **Map Phase**

* Takes input data and processes it into intermediate **(key, value)** pairs.
* Each mapper works **independently and in parallel** on a chunk of data.

### 2. **Shuffle and Sort Phase**

* Groups and sorts the intermediate data by key.
* Ensures all values of the same key are sent to the same reducer.

### 3. **Reduce Phase**

* Takes grouped **(key, list of values)** and produces final output.
* Often used to **aggregate**, **summarize**, or **transform** data.

---

### üõ†Ô∏è Basic Flow Diagram

```text
Input Data ‚Üí Map ‚Üí Shuffle & Sort ‚Üí Reduce ‚Üí Output
```

---
# Hadoop MapReduce pseudo-code:

## Example-1 : Word Count

Word Count Detailed Example:
- Goal: Count occurrences of each word in a document corpus.
- Map: For each word in a line, emit (word, 1).
- Shuffle & Sort: Group all (word, 1) pairs by word.
- Reduce: Sum counts for each word.

```
map(document):
    for word in document.split():
        emit(word, 1)
reduce(word, counts):
    emit(word, sum(counts))
```


## Example-2 : Average Calculation

Average Calculation Example:
- Goal: Compute average value of numbers in a dataset.
- Map: Emit ("key", (number, 1))
- Reduce: Sum numbers and counts, then calculate average.


```
map(record):
    emit("key", (record.value, 1))
reduce("key", list_of_values):
    total,count = 0, 0
    for value, c in list_of_values:
        total += value
        count += c
    emit("key", total / count)
```

## Example-3 : Compute average word length in a corpus. [No need for exam]

---

# MapReduce math
## understanding using numeric solution

![alt text](assets/numerical_mapreduce_solution.png)
![alt text](assets/numerical_mapreduce_solution-1.png)

## MapReduce math 1
![alt text](assets/mapreduce_math_1.jpg)

## MapReduce math 2
![alt text](assets/mapreduce_math_2.jpg)


---
